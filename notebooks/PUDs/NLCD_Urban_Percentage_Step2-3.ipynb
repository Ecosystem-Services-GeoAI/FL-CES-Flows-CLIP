{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8938d2ee-f1b6-4dd0-8f4f-eb2956414356",
   "metadata": {},
   "source": [
    "# Compute the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cf358c-3b7c-490d-981b-b27ac311e281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7303a8-22b0-45b9-afb6-56dd19dc86ca",
   "metadata": {},
   "source": [
    "# Configure pararmters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0954c209-422e-42ee-ba70-100c5bc4b566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metaPath = \"../../metadata/Flickr_FL_Predictions_2014_2019_CLIP-BRF-ZS_1kmGrids.csv\"\n",
    "predLabel = \"CLIP-BRF-ZS\"\n",
    "years_to_filter = [2014, 2015, 2016, 2017, 2018, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2fc70c-d63a-4909-ab9c-22378a67de1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The rule for differernt shape layers.\n",
    "\n",
    "config = {\n",
    "    \"StateServerData\": [\n",
    "        [\"SITE_NAME.notna()\"] #State Park #SITE_NAME #First\n",
    "    ],\n",
    "    \"NationalServerData\": [\n",
    "        [\"PARKNAME.notna()\", #National Park #PARKNAME #Second\n",
    "         \"SITE_NAME.isna()\"] #State Park #SITE_NAME\n",
    "    ],\n",
    "    \"ParkServerData\": {\n",
    "        \"rules\": [\n",
    "            [\"NAME20.notna()\",  #Urban greenspaces #Urban Area #NAME20\n",
    "             \"Park_Name.notna()\", #Park Server #Park_Name  \n",
    "             \"PARKNAME.isna()\", #National Park #PARKNAM\n",
    "             \"SITE_NAME.isna()\"], #State Park #SITE_NAME\n",
    "            [\"NAME20.isna()\",  #Non-urban greenspace, but protect area be priority. #Urban Area #NAME20\n",
    "             \"Park_Name.notna()\", #Park Server #Park_Name\n",
    "             \"IUCN_Cat.isna()\", #Protected Area #IUCN_Cat\n",
    "             \"PARKNAME.isna()\", #National Park #PARKNAME\n",
    "             \"SITE_NAME.isna()\"] #State Park #SITE_NAME\n",
    "        ],\n",
    "        \"subsplits\": {\n",
    "            \"Urban_ParkServerData\": [\"NAME20.notna()\"], #Urban_green space\n",
    "            \"OutUrban_ParkServerData\": [\"NAME20.isna()\"] #Outside of Urban_green space\n",
    "        }\n",
    "    },\n",
    "    \"ProtectedArealData\": [\n",
    "        [\"NAME20.notna()\",  #Protected area in urban, but greenspace (park) be priority). #Urban Area #NAME20\n",
    "         \"Park_Name.isna()\", #Park Server #Park_Name\n",
    "         \"PARKNAME.isna()\", #National Park #PARKNAME\n",
    "         \"SITE_NAME.isna()\", #State Park #SITE_NAME\n",
    "         \"IUCN_Cat.notna()\"],#Protected Area #IUCN_Cat\n",
    "        [\"NAME20.isna()\", #Protecte area in non-urban. #Urban Area #NAME20\n",
    "         \"PARKNAME.isna()\", #National Park #PARKNAME\n",
    "         \"SITE_NAME.isna()\", #State Park #SITE_NAME\n",
    "         \"IUCN_Cat.notna()\"] #Protected Area #IUCN_Cat\n",
    "    ],\n",
    "    \"OtherAreaData\": [\n",
    "        [\"NAME20.isna()\", #Urban Area #NAME20\n",
    "         \"Park_Name.isna()\", #Park Server #Park_Name\n",
    "         \"PARKNAME.isna()\", #National Park #PARKNAME\n",
    "         \"SITE_NAME.isna()\", #State Park #SITE_NAME\n",
    "         \"IUCN_Cat.isna()\"] ,#Protected Area #IUCN_Cat\n",
    "    ]\n",
    "}\n",
    "\n",
    "# The categories for pie (must match keys in your subsets dict).\n",
    "categories = [\n",
    "    \"Urban_ParkServerData\",\n",
    "    \"OutUrban_ParkServerData\",\n",
    "    \"StateServerData\",\n",
    "    \"NationalServerData\",\n",
    "    \"ProtectedArealData\",\n",
    "    \"OtherAreaData\"\n",
    "]\n",
    "\n",
    "count_columns = [\n",
    "    \"Urban greenspaces\",\n",
    "    \"Non-urban greenspaces\",\n",
    "    \"State parks\",\n",
    "    \"National parks\",\n",
    "    \"Protected areas\",\n",
    "    \"Other areas\"\n",
    "]\n",
    "\n",
    "# List of class names\n",
    "class_names = [\"Total\", \"Other\"]\n",
    "\n",
    "class_names_map = {\"Biking\":\"Total\", \"Boating\":\"Total\", \"Camping\":\"Total\", \"Fishing\":\"Total\", \"Hiking\":\"Total\", \n",
    "                   \"Horseback_Riding\":\"Total\",\"Hunting\":\"Total\", \"Shelling\":\"Total\", \"Surfing\":\"Total\", \n",
    "                   \"Swimming\":\"Total\", \"Wildlife_Viewing\":\"Total\",\"Landscape_Aesthetics\":\"Total\", \"Other\":\"Other\"}\n",
    "\n",
    "# NLCD class mapping\n",
    "nlcd_class_map = {\n",
    "    11: \"Water\", 12: \"Water\", 21: \"Developed\", 22: \"Developed\",\n",
    "    23: \"Developed\", 24: \"Developed\", 31: \"Barren\", 41: \"Forest\",\n",
    "    42: \"Forest\", 43: \"Forest\", 51: \"Shrubland\", 52: \"Shrubland\",\n",
    "    71: \"Herbaceous\", 72: \"Herbaceous\", 73: \"Herbaceous\", 74: \"Herbaceous\",\n",
    "    81: \"Pasture/Hay\", 82: \"Cultivated Crops\", 90: \"Wetlands\", 95: \"Wetlands\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bc222-653e-49c5-a2f4-898aa1b0c235",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44964f46-9509-498f-a601-630f82c02386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metaPath)\n",
    "\n",
    "# keep only selected years\n",
    "metadata[\"takendate\"] = pd.to_datetime(metadata[\"takendate\"], errors=\"coerce\")\n",
    "metadata = metadata[metadata.takendate.dt.year.isin(years_to_filter)]\n",
    "\n",
    "metadata[predLabel] = metadata[predLabel].map(class_names_map) #Rename to category level\n",
    "\n",
    "# build GeoDataFrame with correct CRS (WGS84 degrees)\n",
    "geo_df = gpd.GeoDataFrame(\n",
    "    metadata,\n",
    "    geometry=gpd.points_from_xy(metadata.longitude, metadata.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471f9392-b705-4234-8251-45a4747b81a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ownerid', 'latitude', 'longitude', 'takendate', 'SITE_NAME',\n",
       "        'PARKNAME', 'Park_Name', 'IUCN_Cat', 'NAME20', 'NLCD_2023',\n",
       "        'CLIP-BRF-ZS', 'index_right', 'id', 'left', 'top', 'right', 'bottom',\n",
       "        'PUD_ID', 'ownerid_ID'],\n",
       "       dtype='object'),\n",
       " 590378)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns, len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdaddd3-39b0-4d80-b712-1df6a5bf06f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP-BRF-ZS\n",
       "Total    310773\n",
       "Other    279605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df[predLabel].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff5c48d-debf-4d38-b3d3-09f9faa9a574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66652 50381\n"
     ]
    }
   ],
   "source": [
    "metadata_Total = geo_df[geo_df[predLabel] == 'Total'].drop_duplicates(subset=['PUD_ID'])\n",
    "metadata_NoCES = geo_df[geo_df[predLabel] == 'Other'].drop_duplicates(subset=['PUD_ID'])\n",
    "\n",
    "print(len(metadata_Total), len(metadata_NoCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ea828a-e453-400a-88be-38fdcfd25186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateServerData 31642\n",
      "NationalServerData 46148\n",
      "ParkServerData 164732\n",
      "Urban_ParkServerData 155840\n",
      "OutUrban_ParkServerData 8892\n",
      "ProtectedArealData 163862\n",
      "OtherAreaData 183994\n",
      "Total: 755110\n"
     ]
    }
   ],
   "source": [
    "def build_condition(df, cond_str):\n",
    "    col, method = cond_str.split(\".\")\n",
    "    method = method.replace(\"()\", \"\")  # strip parentheses if present\n",
    "    return getattr(df[col], method)()\n",
    "\n",
    "def combine_conditions(df, rule_blocks):\n",
    "    \"\"\"Combine AND inside a block, OR across blocks\"\"\"\n",
    "    or_blocks = []\n",
    "    for and_block in rule_blocks:\n",
    "        conds = [build_condition(df, c) for c in and_block]\n",
    "        and_cond = conds[0]\n",
    "        for c in conds[1:]:\n",
    "            and_cond &= c\n",
    "        or_blocks.append(and_cond)\n",
    "    final_cond = or_blocks[0]\n",
    "    for ob in or_blocks[1:]:\n",
    "        final_cond |= ob\n",
    "    return final_cond\n",
    "\n",
    "def apply_config(df, config):\n",
    "    results = {}\n",
    "    for name, rule_def in config.items():\n",
    "        # allow both old format (list) and dict format (with subsplits)\n",
    "        if isinstance(rule_def, dict):\n",
    "            main_rules = rule_def[\"rules\"]\n",
    "            subsplits = rule_def.get(\"subsplits\", {})\n",
    "        else:\n",
    "            main_rules = rule_def\n",
    "            subsplits = {}\n",
    "\n",
    "        # main subset\n",
    "        cond = combine_conditions(df, main_rules)\n",
    "        subset = df[cond]\n",
    "        results[name] = subset\n",
    "\n",
    "        # subsplits (optional)\n",
    "        for sub_name, sub_rule in subsplits.items():\n",
    "            sub_cond = combine_conditions(subset, [sub_rule])  # treat single split as one block\n",
    "            results[sub_name] = subset[sub_cond]\n",
    "    return results\n",
    "\n",
    "subsets = apply_config(geo_df, config)\n",
    "\n",
    "for name, df in subsets.items():\n",
    "    print(name, len(df))\n",
    "print(\"Total:\", sum(len(df) for df in subsets.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd320182-a6c7-4126-958c-a4d6c0355895",
   "metadata": {},
   "source": [
    "<h1>Urban realted percentage<h1/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e29b6ac-038d-4a56-9eee-e88e547f01ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_total, results_owners, results_avg, results_avgdes = [], [], [], []\n",
    "\n",
    "for cla in class_names:\n",
    "    row_total, row_total_pct = [], []\n",
    "    row_owners, row_owners_pct = [], []\n",
    "    row_avg, row_avg_pct = [], []\n",
    "    row_avgdes, row_avgdes_pct = [], []\n",
    "\n",
    "    # --- collect raw values first ---\n",
    "    total_vals, owner_vals, avg_vals, avgdes_vals = [], [], [], []\n",
    "\n",
    "    for cat in categories:\n",
    "        df_cat = subsets[cat]\n",
    "\n",
    "        # metrics\n",
    "        total_puds = len(df_cat[df_cat[predLabel] == cla].drop_duplicates(subset=['PUD_ID']))\n",
    "        total_owns = len(df_cat[df_cat[predLabel] == cla].drop_duplicates(subset=['ownerid_ID']))\n",
    "        avg_puds = total_puds / len(years_to_filter) if len(years_to_filter) > 0 else 0\n",
    "        # denom = total_owns * len(years_to_filter) if len(years_to_filter) > 0 else 0\n",
    "        # avg_puds_des = total_puds / denom if denom > 0 else 0\n",
    "        total_puds_id = df_cat[df_cat[predLabel] == cla].drop_duplicates(subset=['PUD_ID'])['id'].value_counts()\n",
    "        total_owner_id = df_cat[df_cat[predLabel] == cla].drop_duplicates(subset=['ownerid_ID'])['id'].value_counts()\n",
    "        avg_puds_des_id = (\n",
    "            total_puds_id / total_owner_id / len(years_to_filter)\n",
    "            if len(years_to_filter) > 0 else pd.Series(dtype=float)\n",
    "        )\n",
    "        avg_puds_des = avg_puds_des_id.mean()  if avg_puds_des_id.mean() > 0 else 0\n",
    "\n",
    "        total_vals.append(total_puds)\n",
    "        owner_vals.append(total_owns)\n",
    "        avg_vals.append(avg_puds)\n",
    "        avgdes_vals.append(avg_puds_des)\n",
    "\n",
    "    # --- compute percentages row-wise ---\n",
    "    def to_percent(vals):\n",
    "        row_sum = sum(vals)\n",
    "        return [(v / row_sum * 100) if row_sum > 0 else 0 for v in vals]\n",
    "\n",
    "    total_pct = to_percent(total_vals)\n",
    "    owner_pct = to_percent(owner_vals)\n",
    "    avg_pct = to_percent(avg_vals)\n",
    "    avgdes_pct = to_percent(avgdes_vals)\n",
    "\n",
    "    # append rows with counts + percentages\n",
    "    results_total.append([cla] + total_vals + total_pct)\n",
    "    results_owners.append([cla] + owner_vals + owner_pct)\n",
    "    results_avg.append([cla] + avg_vals + avg_pct)\n",
    "    results_avgdes.append([cla] + avgdes_vals + avgdes_pct)\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "def build_df(results, name):\n",
    "    return pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\"Class\"] + count_columns + [c + \" %\" for c in count_columns]\n",
    "    )\n",
    "\n",
    "df_total = build_df(results_total, \"Total_PUDs\")\n",
    "df_owners = build_df(results_owners, \"Total_Owners\")\n",
    "df_avg = build_df(results_avg, \"Avg_PUDs\")\n",
    "df_avgdes = build_df(results_avgdes, \"Avg_PUDs_Des\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71da26b-0a5c-4960-8a29-84d353e3fce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Save to Excel ---\n",
    "with pd.ExcelWriter(\"../../metadata/CES_Urban_Distribution_Total.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df_total.to_excel(writer, sheet_name=\"Total_PUDs\", index=False)\n",
    "    df_owners.to_excel(writer, sheet_name=\"Total_Owners\", index=False)\n",
    "    df_avg.to_excel(writer, sheet_name=\"Avg_PUDs\", index=False)\n",
    "    df_avgdes.to_excel(writer, sheet_name=\"Avg_PUDs_Des\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a5f43-4f04-4cca-8996-fcd488ae5ad0",
   "metadata": {},
   "source": [
    "<h1>NLCD Percentage<h1/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3203a56d-e3a5-4e0a-90c4-5b1929405e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NLCD_summary(geo_df):\n",
    "    # Initialize summary DataFrame\n",
    "    summary_total_puds = pd.DataFrame()\n",
    "    summary_total_owns = pd.DataFrame()\n",
    "    summary_avg_puds = pd.DataFrame()\n",
    "    summary_avg_puds_des = pd.DataFrame()\n",
    "\n",
    "    # Loop through each CES class\n",
    "    for cla in class_names:\n",
    "        total_puds_table = geo_df[geo_df[predLabel] == cla].drop_duplicates(subset=['PUD_ID'])\n",
    "        total_owns_table = geo_df[geo_df[predLabel] == cla].drop_duplicates(subset=['ownerid_ID'])\n",
    "\n",
    "        mapped_total_puds = total_puds_table[\"NLCD_2023\"].map(nlcd_class_map).value_counts().sort_index()\n",
    "        mapped_total_owns = total_owns_table[\"NLCD_2023\"].map(nlcd_class_map).value_counts().sort_index()\n",
    "        mapped_avg_puds = mapped_total_puds / len(years_to_filter) if len(years_to_filter) > 0 else 0\n",
    "        \n",
    "        mapped_avg_puds_des = {}\n",
    "        # Create new columns with renamed NLCD classes\n",
    "        total_puds_table[\"NLCD_rename\"] = total_puds_table[\"NLCD_2023\"].map(nlcd_class_map)\n",
    "        total_owns_table[\"NLCD_rename\"] = total_owns_table[\"NLCD_2023\"].map(nlcd_class_map)\n",
    "\n",
    "        nlcd_order = [\n",
    "            \"Developed\",\n",
    "            \"Wetlands\",\n",
    "            \"Water\",\n",
    "            \"Pasture/Hay\",\n",
    "            \"Barren\",\n",
    "            \"Forest\",\n",
    "            \"Cultivated Crops\",\n",
    "            \"Herbaceous\",\n",
    "            \"Shrubland\"\n",
    "        ]\n",
    "\n",
    "        for cat in nlcd_order:\n",
    "            # Filter for current class\n",
    "            puds_filtered = total_puds_table[total_puds_table[\"NLCD_rename\"] == cat]\n",
    "            owns_filtered = total_owns_table[total_owns_table[\"NLCD_rename\"] == cat]\n",
    "\n",
    "            # Count occurrences per id\n",
    "            total_puds_id = puds_filtered[\"id\"].value_counts()\n",
    "            total_owner_id = owns_filtered[\"id\"].value_counts()\n",
    "\n",
    "            # Align IDs and compute ratio safely\n",
    "            avg_puds_des_id = (\n",
    "                (total_puds_id / total_owner_id).fillna(0) / len(years_to_filter)\n",
    "                if len(years_to_filter) > 0 else pd.Series(dtype=float)\n",
    "            )\n",
    "\n",
    "            mapped_avg_puds_des[cat] = avg_puds_des_id.mean()      \n",
    "        \n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df_total_puds = mapped_total_puds.reset_index()\n",
    "        df_total_puds.columns = ['class', f'{cla}_count']\n",
    "        df_total_own = mapped_total_owns.reset_index()\n",
    "        df_total_own.columns = ['class', f'{cla}_count']    \n",
    "        df_avg_puds = mapped_avg_puds.reset_index()\n",
    "        df_avg_puds.columns = ['class', f'{cla}_count']\n",
    "        df_avg_puds_des = pd.Series(mapped_avg_puds_des).reset_index()\n",
    "        df_avg_puds_des.columns = ['class', f'{cla}_count']    \n",
    "\n",
    "\n",
    "        total_total_puds = df_total_puds[f'{cla}_count'].sum()\n",
    "        df_total_puds[f'{cla}_percentage'] = (df_total_puds[f'{cla}_count'] / total_total_puds * 100).fillna(0).round(2)\n",
    "        total_total_own = df_total_own[f'{cla}_count'].sum()\n",
    "        df_total_own[f'{cla}_percentage'] = (df_total_own[f'{cla}_count'] / total_total_own * 100).fillna(0).round(2)   \n",
    "        total_avg_puds = df_avg_puds[f'{cla}_count'].sum()\n",
    "        df_avg_puds[f'{cla}_percentage'] = (df_avg_puds[f'{cla}_count'] / total_avg_puds * 100).fillna(0).round(2)\n",
    "        total_avg_puds_des = df_avg_puds_des[f'{cla}_count'].sum()\n",
    "        df_avg_puds_des[f'{cla}_percentage'] = (df_avg_puds_des[f'{cla}_count'] / total_avg_puds_des * 100).fillna(0).round(2)\n",
    "\n",
    "        # Merge into the summary\n",
    "        if summary_total_puds.empty:\n",
    "            summary_total_puds = df_total_puds\n",
    "        else:\n",
    "            summary_total_puds = pd.merge(summary_total_puds, df_total_puds, on='class', how='outer', sort=False)\n",
    "\n",
    "        if summary_total_owns.empty:\n",
    "            summary_total_owns = df_total_own\n",
    "        else:\n",
    "            summary_total_owns = pd.merge(summary_total_owns, df_total_own, on='class', how='outer', sort=False)\n",
    "\n",
    "        if summary_avg_puds.empty:\n",
    "            summary_avg_puds = df_avg_puds\n",
    "        else:\n",
    "            summary_avg_puds = pd.merge(summary_avg_puds, df_avg_puds, on='class', how='outer', sort=False)\n",
    "\n",
    "        if summary_avg_puds_des.empty:\n",
    "            summary_avg_puds_des = df_avg_puds_des\n",
    "        else:\n",
    "            summary_avg_puds_des = pd.merge(summary_avg_puds_des, df_avg_puds_des, on='class', how='outer', sort=False)\n",
    "    \n",
    "    #print(mapped_avg_puds_des)\n",
    "    # Fill missing values\n",
    "    summary_total_puds = summary_total_puds.fillna(0)\n",
    "    summary_total_owns = summary_total_owns.fillna(0)\n",
    "    summary_avg_puds = summary_avg_puds.fillna(0)\n",
    "    summary_avg_puds_des = summary_avg_puds_des.fillna(0)\n",
    "    \n",
    "    return summary_total_puds, summary_total_owns, summary_avg_puds, summary_avg_puds_des\n",
    "\n",
    "def reshape_summary(summary_df, tag):\n",
    "    \"\"\"\n",
    "    Reshape one summary DataFrame into wide format with counts + percentages.\n",
    "    tag = \"Total_PUDs\", \"Total_Owns\", \"Avg_PUDs\", \"Avg_PUDs_Des\"\n",
    "    \"\"\"\n",
    "    # Step 1: Set class index\n",
    "    df = summary_df.set_index(\"class\")\n",
    "    \n",
    "    # Step 2: Split count and percentage parts\n",
    "    count_df = df.filter(like=\"_count\").T\n",
    "    percentage_df = df.filter(like=\"_percentage\").T\n",
    "    \n",
    "    # Step 3: Clean row labels\n",
    "    count_df.index = count_df.index.str.replace(\"_count\", \"\")\n",
    "    percentage_df.index = percentage_df.index.str.replace(\"_percentage\", \"\")\n",
    "    \n",
    "    # Step 4: Add suffixes to columns so we donâ€™t lose CES activity meaning\n",
    "    count_df.columns = [f\"{col}_count\" for col in count_df.columns]\n",
    "    percentage_df.columns = [f\"{col}_percentage\" for col in percentage_df.columns]\n",
    "    \n",
    "    # Step 5: Combine\n",
    "    final_df = pd.concat([count_df, percentage_df], axis=1)\n",
    "    \n",
    "    # Step 6: Reorder by NLCD order\n",
    "    nlcd_order = [\n",
    "        \"Developed\",\n",
    "        \"Wetlands\",\n",
    "        \"Water\",\n",
    "        \"Pasture/Hay\",\n",
    "        \"Barren\",\n",
    "        \"Forest\",\n",
    "        \"Cultivated Crops\",\n",
    "        \"Herbaceous\",\n",
    "        \"Shrubland\"\n",
    "    ]\n",
    "    \n",
    "    count_cols_sorted = [f\"{cls}_count\" for cls in nlcd_order if f\"{cls}_count\" in final_df.columns]\n",
    "    percent_cols_sorted = [f\"{cls}_percentage\" for cls in nlcd_order if f\"{cls}_percentage\" in final_df.columns]\n",
    "    final_df = final_df[count_cols_sorted + percent_cols_sorted]\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "summary_total_puds, summary_total_owns, summary_avg_puds, summary_avg_puds_des = NLCD_summary(geo_df)\n",
    "\n",
    "# Apply to all four\n",
    "final_total_puds = reshape_summary(summary_total_puds, \"Total_PUDs\")\n",
    "final_total_owns = reshape_summary(summary_total_owns, \"Total_Owns\")\n",
    "final_avg_puds = reshape_summary(summary_avg_puds, \"Avg_PUDs\")\n",
    "final_avg_puds_des = reshape_summary(summary_avg_puds_des, \"Avg_PUDs_Des\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e8fac0-37e5-45fc-885c-42d17481f149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Save to Excel with four sheets ---\n",
    "with pd.ExcelWriter(\"../../metadata/CES_NLCD_percentages_Total.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    final_total_puds.to_excel(writer, sheet_name=\"Total_PUDs\")\n",
    "    final_total_owns.to_excel(writer, sheet_name=\"Total_Owns\")\n",
    "    final_avg_puds.to_excel(writer, sheet_name=\"Avg_PUDs\")\n",
    "    final_avg_puds_des.to_excel(writer, sheet_name=\"Avg_PUDs_Des\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6400d-df6d-449e-bfc8-974f6ebf6678",
   "metadata": {},
   "source": [
    "## Other Area NLCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6dc498b-2f2b-4568-998c-4998de34e71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OtherAreaData = subsets['OtherAreaData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc0b8b4-d8d5-462d-aade-4e8725a99eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_total_puds, othe_total_owns, othe_avg_puds, othe_avg_puds_des = NLCD_summary(OtherAreaData)\n",
    "\n",
    "# Apply to all four\n",
    "other_final_total_puds = reshape_summary(other_total_puds, \"Total_PUDs\")\n",
    "other_final_total_owns = reshape_summary(othe_total_owns, \"Total_Owns\")\n",
    "other_final_avg_puds = reshape_summary(othe_avg_puds, \"Avg_PUDs\")\n",
    "other_final_avg_puds_des = reshape_summary(othe_avg_puds_des, \"Avg_PUDs_Des\")\n",
    "\n",
    "# --- Save to Excel with four sheets ---\n",
    "with pd.ExcelWriter(\"../../metadata/CES_NLCD_Other_percentages_Total.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    other_final_total_puds.to_excel(writer, sheet_name=\"Total_PUDs\")\n",
    "    other_final_total_owns.to_excel(writer, sheet_name=\"Total_Owns\")\n",
    "    other_final_avg_puds.to_excel(writer, sheet_name=\"Avg_PUDs\")\n",
    "    other_final_avg_puds_des.to_excel(writer, sheet_name=\"Avg_PUDs_Des\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb87894-064f-49d3-9749-fd5d9daa4098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL-CES-Flows-CLIP",
   "language": "python",
   "name": "fl-ces-flows-clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
